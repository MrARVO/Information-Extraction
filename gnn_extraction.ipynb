{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a684ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import yaml\n",
    "import ast\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Queue, Process, Pool\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, GATv2Conv, SAGEConv\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b662b35",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f665b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bec70a",
   "metadata": {},
   "source": [
    "## сайты в графы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10d4b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# полезные функции\n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "def rgba2rgb(rgba: tuple[int, int, int, float], background: tuple[int, int, int] = (255, 255, 255)):\n",
    "    return [\n",
    "        round(((1 - rgba[3]) * background[0]) + (rgba[3] * rgba[0])),\n",
    "        round(((1 - rgba[3]) * background[1]) + (rgba[3] * rgba[1])),\n",
    "        round(((1 - rgba[3]) * background[2]) + (rgba[3] * rgba[2])),\n",
    "    ]\n",
    "\n",
    "\n",
    "def check_overlap(l1, r1, l2, r2):\n",
    "    rect1_corners = [(l1.x, l1.y), (r1.x, r1.y)]\n",
    "    rect2_corners = [(l2.x, l2.y), (r2.x, r2.y)]\n",
    "    \n",
    "    for corner in rect1_corners:\n",
    "        if (corner[0] >= rect2_corners[0][0] and corner[0] <= rect2_corners[1][0] and\n",
    "            corner[1] >= rect2_corners[0][1] and corner[1] <= rect2_corners[1][1]):\n",
    "            return True\n",
    "    \n",
    "    for corner in rect2_corners:\n",
    "        if (corner[0] >= rect1_corners[0][0] and corner[0] <= rect1_corners[1][0] and\n",
    "            corner[1] >= rect1_corners[0][1] and corner[1] <= rect1_corners[1][1]):\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "828096ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 105 ms, sys: 225 ms, total: 331 ms\n",
      "Wall time: 10min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "graphs_folder = './graphs'\n",
    "\n",
    "def func(file):\n",
    "    df = pd.read_csv(f'{filepath}/{file}')\n",
    "    \n",
    "    fl = file[:-4]\n",
    "    if not os.path.exists(graphs_folder):\n",
    "        os.makedirs(graphs_folder)\n",
    "    \n",
    "    for site in range(len(df)):\n",
    "        blocks = df['Blocks'][site]\n",
    "        blocks = ast.literal_eval(blocks)\n",
    "        #print(blocks)\n",
    "        \n",
    "        label_one = df['MatchingBlocks'][site]\n",
    "        \n",
    "        good_blocks = []\n",
    "        for b in blocks:\n",
    "            if (blocks[b]['p_tag'] != 'script' and blocks[b]['p_tag'] != 'link' and\n",
    "                blocks[b]['p_tag'] != 'style' and \n",
    "                (blocks[b]['size']['width'] * blocks[b]['size']['height']) != 0):\n",
    "                \n",
    "                good_blocks.append(b)\n",
    "\n",
    "        G = nx.Graph()\n",
    "        for i in range(len(good_blocks)):\n",
    "            cur_dict = blocks[good_blocks[i]]\n",
    "            \n",
    "            location = cur_dict['location']\n",
    "    \n",
    "            size_w = cur_dict['size']['width']\n",
    "            size_h = cur_dict['size']['height']\n",
    "\n",
    "            if size_w * size_h == 0:\n",
    "                fullness = 0\n",
    "            else:\n",
    "                fullness = round(float(cur_dict['font-size'][:-2]) * cur_dict['length'] / (size_w * size_h), 2)\n",
    "\n",
    "            font_color = cur_dict['font-color']\n",
    "            if font_color.find('rgba') != -1:\n",
    "                font_color = font_color[5:-1].split(',')\n",
    "                font_color = list(map(float, font_color))\n",
    "                font_color = rgba2rgb(font_color)\n",
    "            else:\n",
    "                font_color = font_color[4:-1].split(',')\n",
    "                font_color = list(map(float, font_color))\n",
    "\n",
    "            bg_color = cur_dict['bg-color']\n",
    "            if bg_color.find('rgba') != -1:\n",
    "                bg_color = bg_color[5:-1].split(',')\n",
    "                bg_color = list(map(float, bg_color))\n",
    "                bg_color = rgba2rgb(bg_color)\n",
    "            else:\n",
    "                bg_color = bg_color[4:-1].split(',')\n",
    "                bg_color = list(map(float, bg_color))\n",
    "\n",
    "            color = [el1 - el2 for (el1, el2) in zip(font_color, bg_color)]\n",
    "\n",
    "            has_img = int(cur_dict['hasImg'])\n",
    "\n",
    "            #y = cur_dict['label']\n",
    "            if good_blocks[i] in label_one:\n",
    "                y = 1;\n",
    "            else:\n",
    "                y = 0;\n",
    "\n",
    "            G.add_node(i,\n",
    "                       x = [location['x'], location['y'], size_w, size_h, fullness,\n",
    "                            color[0], color[1], color[2], has_img],\n",
    "                       y = y)\n",
    "\n",
    "        for i in range(len(good_blocks)):\n",
    "            l1 = Point(blocks[good_blocks[i]]['location']['x'],\n",
    "                        blocks[good_blocks[i]]['location']['y'])\n",
    "\n",
    "            r1 = Point(blocks[good_blocks[i]]['location']['x'] + blocks[good_blocks[i]]['size']['width'],\n",
    "                        blocks[good_blocks[i]]['location']['y'] + blocks[good_blocks[i]]['size']['height'])\n",
    "\n",
    "            for j in range(i+1, len(good_blocks)):\n",
    "                l2 = Point(blocks[good_blocks[j]]['location']['x'],\n",
    "                            blocks[good_blocks[j]]['location']['y'])\n",
    "\n",
    "                r2 = Point(blocks[good_blocks[j]]['location']['x'] + blocks[good_blocks[j]]['size']['width'],\n",
    "                            blocks[good_blocks[j]]['location']['y'] + blocks[good_blocks[j]]['size']['height'])\n",
    "\n",
    "                if check_overlap(l1, r1, l2, r2):\n",
    "                    G.add_edge(i, j)\n",
    "\n",
    "        #G = G.subgraph(nx.node_connected_component(G, 0))\n",
    "        if nx.number_connected_components(G) > 0:\n",
    "            G_sorted = sorted(nx.connected_components(G), key=len, reverse=True)\n",
    "            G = G.subgraph(G_sorted[0])\n",
    "            pickle.dump(G, open(f'./{graphs_folder}/{fl}_{site}.pkl', 'wb'))\n",
    "\n",
    "\n",
    "result = Parallel(n_jobs=-1)(delayed(func)(file) for file in os.listdir(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b95abab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc0cdce8",
   "metadata": {},
   "source": [
    "## проверка качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2edf16b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1824/1824 [00:45<00:00, 40.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp num average:\t 1.0\n",
      "comp size average:\t 785.2708333333334\n",
      "node num average:\t 785.2708333333334\n",
      "edge num average:\t 13104.327302631578\n",
      "labels average:\t\t 47.0515350877193\n",
      "labels total:\t\t 85822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "comps = 0\n",
    "comp_size = 0\n",
    "nodes = 0\n",
    "edges = 0\n",
    "label = 0\n",
    "    \n",
    "for grph in tqdm(os.listdir(graphs_folder)):\n",
    "    G = pickle.load(open(f'./{graphs_folder}/{grph}', 'rb'))\n",
    "        \n",
    "    for component in nx.connected_components(G):\n",
    "        comp_size += len(component)\n",
    "        \n",
    "    comps += nx.number_connected_components(G)\n",
    "    nodes += G.number_of_nodes()\n",
    "    edges += G.number_of_edges()\n",
    "        \n",
    "    for n in G.nodes:\n",
    "        label += G.nodes[n]['y']\n",
    "\n",
    "\n",
    "num = len(os.listdir(graphs_folder))\n",
    "    \n",
    "print('comp num average:\\t', comps/num)\n",
    "print('comp size average:\\t', comp_size/num)\n",
    "print('node num average:\\t',nodes/num)\n",
    "print('edge num average:\\t', edges/num)\n",
    "print('labels average:\\t\\t', label/num)\n",
    "print('labels total:\\t\\t', label)\n",
    "#print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f048f025",
   "metadata": {},
   "source": [
    "# DL магия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695db4bf",
   "metadata": {},
   "source": [
    "### данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68754a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_folder = './graphs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32671419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1824/1824 [02:07<00:00, 14.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "for grph in tqdm(os.listdir(graphs_folder)):\n",
    "    G = pickle.load(open(f'{graphs_folder}/{grph}', 'rb'))\n",
    "    \n",
    "    lbl = 0\n",
    "    for n in G.nodes:\n",
    "        lbl += G.nodes[n]['y']\n",
    "    \n",
    "    if lbl > 0:\n",
    "        data_list.append(from_networkx(G))\n",
    "\n",
    "\n",
    "random.Random(42).shuffle(data_list)\n",
    "print(len(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5901da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(data_list[:1125], batch_size=125, shuffle=True)\n",
    "test_loader = DataLoader(data_list[1125:], batch_size=125, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa7e8c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be0a13db",
   "metadata": {},
   "source": [
    "### Модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f70ba557",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(9, hidden)\n",
    "        self.conv2 = GCNConv(hidden, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe039499",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN_1, self).__init__()\n",
    "        self.conv1 = GCNConv(9, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "865f947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, hidden):\n",
    "        super(SAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(9, hidden)\n",
    "        self.conv2 = SAGEConv(hidden, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9ae5822",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE_1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SAGE_1, self).__init__()\n",
    "        self.conv1 = SAGEConv(9, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78adfb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, hidden):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(9, hidden)\n",
    "        self.conv2 = GATConv(hidden, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11bb8415",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT_1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT_1, self).__init__()\n",
    "        self.conv1 = GATConv(9, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c7f6db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATv2(torch.nn.Module):\n",
    "    def __init__(self, hidden):\n",
    "        super(GATv2, self).__init__()\n",
    "        self.conv1 = GATv2Conv(9, hidden)\n",
    "        self.conv2 = GATv2Conv(hidden, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d558a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATv2_1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GATv2_1, self).__init__()\n",
    "        self.conv1 = GATv2Conv(9, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42107a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c8c1a9a",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5954b797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(output, y_batch):\n",
    "    return torch.nn.NLLLoss()(output, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e51a5a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████                                 | 1/4 [02:06<06:18, 126.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden:\t 4\n",
      "epoch:\t 2\n",
      "f1:\t 0.558\n",
      "roc-auc: 0.741\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████                      | 2/4 [04:10<04:10, 125.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden:\t 5\n",
      "epoch:\t 3\n",
      "f1:\t 0.614\n",
      "roc-auc: 0.76\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████           | 3/4 [06:17<02:06, 126.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden:\t 6\n",
      "epoch:\t 6\n",
      "f1:\t 0.621\n",
      "roc-auc: 0.841\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 4/4 [08:24<00:00, 126.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden:\t 7\n",
      "epoch:\t 6\n",
      "f1:\t 0.621\n",
      "roc-auc: 0.846\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def best_model_creation(hidden, epochs_num, f1_best, path, name):\n",
    "    flag = 0\n",
    "    f1 = round(sum(f1_best) / len(f1_best), 2)\n",
    "    \n",
    "    for i in range(100):\n",
    "        model = SAGE(hidden).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "        for epoch in range(epochs_num):\n",
    "            # train\n",
    "            for dt in train_loader:\n",
    "                data = dt.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                out = model(data)\n",
    "                loss = loss_func(out, data.y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "            # test\n",
    "            f1_log, acc_log, roc_auc_log = [], [], []\n",
    "            model.eval()\n",
    "\n",
    "            for dt in test_loader:\n",
    "                data = dt.to(device)\n",
    "\n",
    "                output = model(data)\n",
    "                pred = pred = torch.argmax(output, dim=1)\n",
    "\n",
    "                f1_log.append(f1_score(data.y.cpu().numpy().flatten(), pred.cpu().numpy().flatten()))\n",
    "\n",
    "                if np.std(data.y.cpu().numpy().flatten()) == 0:\n",
    "                    roc_auc = 0\n",
    "                else:\n",
    "                    roc_auc = roc_auc_score(data.y.cpu().numpy().flatten(),\n",
    "                                                nn.Softmax(dim=1)(output)[:, 1].detach().cpu().numpy().flatten())\n",
    "\n",
    "                roc_auc_log.append(roc_auc)\n",
    "\n",
    "                acc = torch.mean((pred == data.y).float())\n",
    "                acc_log.append(acc.cpu().numpy())\n",
    "\n",
    "            if ((sum(f1_log) / len(f1_log)) > (sum(f1_best) / len(f1_best))):\n",
    "                flag = 1\n",
    "                f1_best = f1_log\n",
    "                f1 = round(sum(f1_best) / len(f1_best), 3)\n",
    "                roc_auc_best = round(sum(roc_auc_log) / len(roc_auc_log), 3)\n",
    "                epoch_best = epoch\n",
    "                best_model = model\n",
    "    \n",
    "    if flag == 1:\n",
    "        print('hidden:\\t', hidden)\n",
    "        print('epoch:\\t', epoch_best)\n",
    "        print('f1:\\t', f1)\n",
    "        print('roc-auc:', roc_auc_best)\n",
    "        print()\n",
    "        \n",
    "        torch.save(best_model.state_dict(), f'{path}/{name}_{hidden}_{epoch_best}_{f1}_{roc_auc_best}.graph.state')\n",
    "        torch.save(best_model, f'{path}/{name}_{hidden}_{epoch_best}_{f1}_{roc_auc_best}.graph')\n",
    "    \n",
    "    return f1_best\n",
    "\n",
    "\n",
    "f1_best = [0.2]\n",
    "for h in trange(4, 8):\n",
    "    f1_best = best_model_creation(h, 10, f1_best, './best_models/SAGE', 'SAGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b1b388da",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bec1515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d4209b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:\t 0.95\n",
      "f1:\t 0.67\n",
      "roc_auc: 0.91\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(data_list, batch_size=147, shuffle=True)\n",
    "model = torch.load('./best_models/SAGE/SAGE_4_5_0.653_0.916.graph')\n",
    "model.eval()\n",
    "\n",
    "roc_auc_log, f1_log, acc_log = [], [], []\n",
    "\n",
    "for dt in loader:\n",
    "    data = dt.to(device)\n",
    "\n",
    "    output = model(data)\n",
    "    pred = pred = torch.argmax(output, dim=1)\n",
    "\n",
    "    f1_log.append(f1_score(data.y.cpu().numpy().flatten(), pred.cpu().numpy().flatten()))\n",
    "\n",
    "    if np.std(data.y.cpu().numpy().flatten()) == 0:\n",
    "        roc_auc = 0\n",
    "    else:\n",
    "        roc_auc = roc_auc_score(data.y.cpu().numpy().flatten(),\n",
    "                                    nn.Softmax(dim=1)(output)[:, 1].detach().cpu().numpy().flatten())\n",
    "\n",
    "    roc_auc_log.append(roc_auc)\n",
    "\n",
    "    acc = torch.mean((pred == data.y).float())\n",
    "    acc_log.append(acc.cpu().numpy())\n",
    "\n",
    "\n",
    "print('SAGE')\n",
    "print('acc:\\t', round(sum(acc_log) / len(acc_log), 2))\n",
    "print('f1:\\t', round(sum(f1_log) / len(f1_log), 2))\n",
    "print('roc_auc:', round(sum(roc_auc_log) / len(roc_auc_log), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a86e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538973b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f98b12f5",
   "metadata": {},
   "source": [
    "# DOM дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddb37679",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_folder = './graphs_dom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9733600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.8 ms, sys: 196 ms, total: 236 ms\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "graphs_folder = './graphs_dom'\n",
    "\n",
    "def func(file):\n",
    "    df = pd.read_csv(f'{filepath}/{file}')\n",
    "    \n",
    "    fl = file[:-4]\n",
    "    if not os.path.exists(graphs_folder):\n",
    "        os.makedirs(graphs_folder)\n",
    "    \n",
    "    for site in range(len(df)):\n",
    "        blocks = df['Blocks'][site]\n",
    "        blocks = ast.literal_eval(blocks)\n",
    "        #print(blocks)\n",
    "        \n",
    "        label_one = df['MatchingBlocks'][site]\n",
    "        \n",
    "        good_blocks = []\n",
    "        for b in blocks:\n",
    "            if (blocks[b]['p_tag'] != 'script' and blocks[b]['p_tag'] != 'link' and\n",
    "                blocks[b]['p_tag'] != 'style' and \n",
    "                (blocks[b]['size']['width'] * blocks[b]['size']['height']) != 0):\n",
    "                \n",
    "                good_blocks.append(b)\n",
    "\n",
    "        G = nx.Graph()\n",
    "        node_dict = {}\n",
    "        for i in range(len(good_blocks)):\n",
    "            cur_dict = blocks[good_blocks[i]]\n",
    "            \n",
    "            node_dict[good_blocks[i]] = i\n",
    "            \n",
    "            location = cur_dict['location']\n",
    "    \n",
    "            size_w = cur_dict['size']['width']\n",
    "            size_h = cur_dict['size']['height']\n",
    "\n",
    "            if size_w * size_h == 0:\n",
    "                fullness = 0\n",
    "            else:\n",
    "                fullness = round(float(cur_dict['font-size'][:-2]) * cur_dict['length'] / (size_w * size_h), 2)\n",
    "\n",
    "            font_color = cur_dict['font-color']\n",
    "            if font_color.find('rgba') != -1:\n",
    "                font_color = font_color[5:-1].split(',')\n",
    "                font_color = list(map(float, font_color))\n",
    "                font_color = rgba2rgb(font_color)\n",
    "            else:\n",
    "                font_color = font_color[4:-1].split(',')\n",
    "                font_color = list(map(float, font_color))\n",
    "\n",
    "            bg_color = cur_dict['bg-color']\n",
    "            if bg_color.find('rgba') != -1:\n",
    "                bg_color = bg_color[5:-1].split(',')\n",
    "                bg_color = list(map(float, bg_color))\n",
    "                bg_color = rgba2rgb(bg_color)\n",
    "            else:\n",
    "                bg_color = bg_color[4:-1].split(',')\n",
    "                bg_color = list(map(float, bg_color))\n",
    "\n",
    "            color = [el1 - el2 for (el1, el2) in zip(font_color, bg_color)]\n",
    "\n",
    "            has_img = int(cur_dict['hasImg'])\n",
    "\n",
    "            #y = cur_dict['label']\n",
    "            if good_blocks[i] in label_one:\n",
    "                y = 1;\n",
    "            else:\n",
    "                y = 0;\n",
    "\n",
    "            G.add_node(i,\n",
    "                       x = [location['x'], location['y'], size_w, size_h, fullness,\n",
    "                            color[0], color[1], color[2], has_img],\n",
    "                       y = y)\n",
    "\n",
    "        for i in range(len(good_blocks)):\n",
    "            parent = good_blocks[i][:-(len(good_blocks[i].split('/')[-1]) + 1)]\n",
    "            if parent in node_dict:\n",
    "                G.add_edge(node_dict[good_blocks[i]], node_dict[parent])\n",
    "\n",
    "        #G = G.subgraph(nx.node_connected_component(G, 0))\n",
    "        if nx.number_connected_components(G) > 0:\n",
    "            G_sorted = sorted(nx.connected_components(G), key=len, reverse=True)\n",
    "            G = G.subgraph(G_sorted[0])\n",
    "            pickle.dump(G, open(f'./{graphs_folder}/{fl}_{site}.pkl', 'wb'))\n",
    "\n",
    "        \n",
    "result = Parallel(n_jobs=-1)(delayed(func)(file) for file in os.listdir(filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85e8525",
   "metadata": {},
   "source": [
    "### проверка качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aeda6574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1824/1824 [00:15<00:00, 120.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp num average:\t 1.0\n",
      "comp size average:\t 775.2549342105264\n",
      "node num average:\t 775.2549342105264\n",
      "edge num average:\t 774.2549342105264\n",
      "labels average:\t\t 48.50109649122807\n",
      "labels total:\t\t 88466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "comps = 0\n",
    "comp_size = 0\n",
    "nodes = 0\n",
    "edges = 0\n",
    "label = 0\n",
    "    \n",
    "for grph in tqdm(os.listdir(graphs_folder)):\n",
    "    G = pickle.load(open(f'./{graphs_folder}/{grph}', 'rb'))\n",
    "        \n",
    "    for component in nx.connected_components(G):\n",
    "        comp_size += len(component)\n",
    "        \n",
    "    comps += nx.number_connected_components(G)\n",
    "    nodes += G.number_of_nodes()\n",
    "    edges += G.number_of_edges()\n",
    "        \n",
    "    for n in G.nodes:\n",
    "        label += G.nodes[n]['y']\n",
    "\n",
    "\n",
    "num = len(os.listdir(graphs_folder))\n",
    "    \n",
    "print('comp num average:\\t', comps/num)\n",
    "print('comp size average:\\t', comp_size/num)\n",
    "print('node num average:\\t',nodes/num)\n",
    "print('edge num average:\\t', edges/num)\n",
    "print('labels average:\\t\\t', label/num)\n",
    "print('labels total:\\t\\t', label)\n",
    "#print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bf1b42",
   "metadata": {},
   "source": [
    "### Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "073dd644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1824/1824 [00:29<00:00, 61.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "for grph in tqdm(os.listdir(graphs_folder)):\n",
    "    G = pickle.load(open(f'{graphs_folder}/{grph}', 'rb'))\n",
    "    \n",
    "    lbl = 0\n",
    "    for n in G.nodes:\n",
    "        lbl += G.nodes[n]['y']\n",
    "    \n",
    "    if lbl > 0:\n",
    "        data_list.append(from_networkx(G))\n",
    "\n",
    "\n",
    "random.Random(42).shuffle(data_list)\n",
    "print(len(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d370c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(data_list[:1202], batch_size=121, shuffle=True)\n",
    "test_loader = DataLoader(data_list[1202:], batch_size=80, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a818060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a48ecd70",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6e7bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(output, y_batch):\n",
    "    return torch.nn.NLLLoss()(output, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "106be8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████▎                                 | 1/4 [01:00<03:01, 60.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden:\t 4\n",
      "epoch:\t 1\n",
      "f1:\t 0.582\n",
      "roc-auc: 0.85\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████▊           | 3/4 [03:04<01:01, 61.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden:\t 6\n",
      "epoch:\t 3\n",
      "f1:\t 0.585\n",
      "roc-auc: 0.778\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [04:07<00:00, 61.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden:\t 7\n",
      "epoch:\t 7\n",
      "f1:\t 0.614\n",
      "roc-auc: 0.847\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def best_model_creation(hidden, epochs_num, f1_best, path, name):\n",
    "    flag = 0\n",
    "    f1 = round(sum(f1_best) / len(f1_best), 2)\n",
    "    \n",
    "    for i in range(100):\n",
    "        model = SAGE(hidden).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "        for epoch in range(epochs_num):\n",
    "            # train\n",
    "            for dt in train_loader:\n",
    "                data = dt.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                out = model(data)\n",
    "                loss = loss_func(out, data.y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "            # test\n",
    "            f1_log, acc_log, roc_auc_log = [], [], []\n",
    "            model.eval()\n",
    "\n",
    "            for dt in test_loader:\n",
    "                data = dt.to(device)\n",
    "\n",
    "                output = model(data)\n",
    "                pred = pred = torch.argmax(output, dim=1)\n",
    "\n",
    "                f1_log.append(f1_score(data.y.cpu().numpy().flatten(), pred.cpu().numpy().flatten()))\n",
    "\n",
    "                if np.std(data.y.cpu().numpy().flatten()) == 0:\n",
    "                    roc_auc = 0\n",
    "                else:\n",
    "                    roc_auc = roc_auc_score(data.y.cpu().numpy().flatten(),\n",
    "                                                nn.Softmax(dim=1)(output)[:, 1].detach().cpu().numpy().flatten())\n",
    "\n",
    "                roc_auc_log.append(roc_auc)\n",
    "\n",
    "                acc = torch.mean((pred == data.y).float())\n",
    "                acc_log.append(acc.cpu().numpy())\n",
    "\n",
    "            if ((sum(f1_log) / len(f1_log)) > (sum(f1_best) / len(f1_best))):\n",
    "                flag = 1\n",
    "                f1_best = f1_log\n",
    "                f1 = round(sum(f1_best) / len(f1_best), 3)\n",
    "                roc_auc_best = round(sum(roc_auc_log) / len(roc_auc_log), 3)\n",
    "                epoch_best = epoch\n",
    "                best_model = model\n",
    "    \n",
    "    if flag == 1:\n",
    "        print('hidden:\\t', hidden)\n",
    "        print('epoch:\\t', epoch_best)\n",
    "        print('f1:\\t', f1)\n",
    "        print('roc-auc:', roc_auc_best)\n",
    "        print()\n",
    "        \n",
    "        torch.save(best_model.state_dict(), f'{path}/{name}_{hidden}_{epoch_best}_{f1}_{roc_auc_best}.graph.state')\n",
    "        torch.save(best_model, f'{path}/{name}_{hidden}_{epoch_best}_{f1}_{roc_auc_best}.graph')\n",
    "    \n",
    "    return f1_best\n",
    "\n",
    "\n",
    "f1_best = [0.2]\n",
    "for h in trange(4, 8):\n",
    "    f1_best = best_model_creation(h, 10, f1_best, './best_models_dom/SAGE', 'SAGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dd1c70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
